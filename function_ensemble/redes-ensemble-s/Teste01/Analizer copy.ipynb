{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27848/787217452.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_excel(file_name):\n",
    "    df = pd.read_excel(file_name)\n",
    "    return df\n",
    "\n",
    "def read_txt(file_name):\n",
    "    file = open(file_name)\n",
    "    lines = file.readlines()\n",
    "    return(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def get_files(subfolder, extension):\n",
    "    dir = f\"{os.getcwd()}/content/{subfolder}/\"\n",
    "    tables = glob.glob(f\"{dir}*.{extension}\")\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analizer:\n",
    "    def __init__(self, boundary):\n",
    "        self.results = get_files(subfolder=\"results\", extension=\"xlsx\")\n",
    "        self.results_df = pd.DataFrame()\n",
    "        self.boundary = boundary\n",
    "    \n",
    "    def has_minimum_requirements(self, df, sort_by=\"r2\"):\n",
    "        sorted_df = df.sort_values(by=sort_by, ascending=False)\n",
    "        top_r2 = sorted_df.head(1)[sort_by].values[0]\n",
    "        if top_r2 < self.boundary:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def concatenate_df(self, df, architecture):\n",
    "        if self.has_minimum_requirements(df):\n",
    "            df['Architecture'] = architecture\n",
    "            df = df.rename(columns={'Unnamed: 0': 'model'})\n",
    "            self.results_df = pd.concat([self.results_df, df], ignore_index=True) \n",
    "\n",
    "    def create_results_df(self):\n",
    "        for file in self.results:\n",
    "            df = read_excel(file)\n",
    "            architecture = read_txt(file.replace(\".xlsx\", \".txt\"))\n",
    "            self.concatenate_df(df, architecture)\n",
    "        self.results_df = self.results_df.sort_values(by=\"r2\", ascending=False, ignore_index=True)\n",
    "\n",
    "    def discard_below_average(self, sort_by):\n",
    "        column_mean = self.results_df[sort_by].mean()      \n",
    "        self.results_df = self.results_df[self.results_df[sort_by] >= column_mean]\n",
    "    \n",
    "    def discard_high_standard_deviation(self):\n",
    "        r2_val, r2_test = self.results_df['r2_val'], self.results_df['r2_test']\n",
    "        std_devs = np.abs(r2_val - r2_test)\n",
    "        mean_std_dev = std_devs.mean()\n",
    "        self.results_df = self.results_df[std_devs < mean_std_dev]\n",
    "\n",
    "    def clean_folder(self, subfolder, extension, remove_last=True):\n",
    "        files = get_files(subfolder, extension)\n",
    "        models = self.results_df[\"model\"]\n",
    "        if (remove_last):\n",
    "            models = models.apply(lambda x: '_'.join(x.rsplit('_', 1)[:-1]))\n",
    "        for file in files:\n",
    "            file_name = os.path.basename(file).split('.')[0]\n",
    "            file_parts = file_name.split('_')            \n",
    "            dataset_model = f\"model_{file_parts[1]}_{file_parts[2]}\" \n",
    "            if (remove_last == False):\n",
    "                dataset_model = (f\"{dataset_model}_{file_parts[3]}\")\n",
    "            if dataset_model not in models.values:\n",
    "                os.remove(file)   \n",
    "        \n",
    "    def Analize(self):\n",
    "        self.create_results_df()\n",
    "        self.discard_below_average(sort_by=\"r2_sup\")\n",
    "        self.discard_below_average(sort_by=\"r2_vt\")\n",
    "        self.discard_high_standard_deviation()\n",
    "        self.results_df.to_excel(f\"better_results.xlsx\", index=True)\n",
    "        display(self.results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_sup</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>r2_vt</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_sup</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>mse_val</th>\n",
       "      <th>mse_vt</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rsd</th>\n",
       "      <th>aic</th>\n",
       "      <th>bic</th>\n",
       "      <th>Architecture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>model_30_7_10</td>\n",
       "      <td>0.988412</td>\n",
       "      <td>0.804699</td>\n",
       "      <td>0.981097</td>\n",
       "      <td>0.966296</td>\n",
       "      <td>0.977518</td>\n",
       "      <td>0.077488</td>\n",
       "      <td>1.305981</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.147212</td>\n",
       "      <td>0.183195</td>\n",
       "      <td>0.503922</td>\n",
       "      <td>0.278367</td>\n",
       "      <td>1.011124</td>\n",
       "      <td>0.290217</td>\n",
       "      <td>103.115264</td>\n",
       "      <td>162.840180</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>model_30_7_9</td>\n",
       "      <td>0.988396</td>\n",
       "      <td>0.803299</td>\n",
       "      <td>0.982553</td>\n",
       "      <td>0.968587</td>\n",
       "      <td>0.979168</td>\n",
       "      <td>0.077593</td>\n",
       "      <td>1.315337</td>\n",
       "      <td>0.202296</td>\n",
       "      <td>0.137205</td>\n",
       "      <td>0.169750</td>\n",
       "      <td>0.526308</td>\n",
       "      <td>0.278555</td>\n",
       "      <td>1.011139</td>\n",
       "      <td>0.290414</td>\n",
       "      <td>103.112559</td>\n",
       "      <td>162.837475</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>model_30_7_11</td>\n",
       "      <td>0.988338</td>\n",
       "      <td>0.805871</td>\n",
       "      <td>0.979728</td>\n",
       "      <td>0.964110</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.077983</td>\n",
       "      <td>1.298140</td>\n",
       "      <td>0.235055</td>\n",
       "      <td>0.156762</td>\n",
       "      <td>0.195908</td>\n",
       "      <td>0.483683</td>\n",
       "      <td>0.279254</td>\n",
       "      <td>1.011195</td>\n",
       "      <td>0.291143</td>\n",
       "      <td>103.102527</td>\n",
       "      <td>162.827443</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>model_30_7_8</td>\n",
       "      <td>0.988260</td>\n",
       "      <td>0.801626</td>\n",
       "      <td>0.984098</td>\n",
       "      <td>0.970958</td>\n",
       "      <td>0.980902</td>\n",
       "      <td>0.078506</td>\n",
       "      <td>1.326527</td>\n",
       "      <td>0.184385</td>\n",
       "      <td>0.126851</td>\n",
       "      <td>0.155618</td>\n",
       "      <td>0.551029</td>\n",
       "      <td>0.280189</td>\n",
       "      <td>1.011270</td>\n",
       "      <td>0.292117</td>\n",
       "      <td>103.089163</td>\n",
       "      <td>162.814079</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>model_30_7_12</td>\n",
       "      <td>0.988199</td>\n",
       "      <td>0.806856</td>\n",
       "      <td>0.978443</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.974490</td>\n",
       "      <td>0.078913</td>\n",
       "      <td>1.291553</td>\n",
       "      <td>0.249950</td>\n",
       "      <td>0.165786</td>\n",
       "      <td>0.207868</td>\n",
       "      <td>0.465406</td>\n",
       "      <td>0.280915</td>\n",
       "      <td>1.011329</td>\n",
       "      <td>0.292874</td>\n",
       "      <td>103.078819</td>\n",
       "      <td>162.803734</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>model_30_7_13</td>\n",
       "      <td>0.988014</td>\n",
       "      <td>0.807686</td>\n",
       "      <td>0.977242</td>\n",
       "      <td>0.960107</td>\n",
       "      <td>0.973116</td>\n",
       "      <td>0.080147</td>\n",
       "      <td>1.286007</td>\n",
       "      <td>0.263884</td>\n",
       "      <td>0.174246</td>\n",
       "      <td>0.219065</td>\n",
       "      <td>0.448909</td>\n",
       "      <td>0.283103</td>\n",
       "      <td>1.011506</td>\n",
       "      <td>0.295155</td>\n",
       "      <td>103.047783</td>\n",
       "      <td>162.772698</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>model_30_7_7</td>\n",
       "      <td>0.987963</td>\n",
       "      <td>0.799620</td>\n",
       "      <td>0.985734</td>\n",
       "      <td>0.973369</td>\n",
       "      <td>0.982713</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>1.339942</td>\n",
       "      <td>0.165412</td>\n",
       "      <td>0.116318</td>\n",
       "      <td>0.140865</td>\n",
       "      <td>0.578278</td>\n",
       "      <td>0.283705</td>\n",
       "      <td>1.011555</td>\n",
       "      <td>0.295783</td>\n",
       "      <td>103.039285</td>\n",
       "      <td>162.764201</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>model_30_7_14</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>0.976121</td>\n",
       "      <td>0.958303</td>\n",
       "      <td>0.971835</td>\n",
       "      <td>0.081583</td>\n",
       "      <td>1.281326</td>\n",
       "      <td>0.276878</td>\n",
       "      <td>0.182127</td>\n",
       "      <td>0.229502</td>\n",
       "      <td>0.434031</td>\n",
       "      <td>0.285627</td>\n",
       "      <td>1.011712</td>\n",
       "      <td>0.297787</td>\n",
       "      <td>103.012270</td>\n",
       "      <td>162.737185</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>model_30_7_15</td>\n",
       "      <td>0.987567</td>\n",
       "      <td>0.808978</td>\n",
       "      <td>0.975079</td>\n",
       "      <td>0.956630</td>\n",
       "      <td>0.970645</td>\n",
       "      <td>0.083142</td>\n",
       "      <td>1.277367</td>\n",
       "      <td>0.288962</td>\n",
       "      <td>0.189434</td>\n",
       "      <td>0.239198</td>\n",
       "      <td>0.420625</td>\n",
       "      <td>0.288344</td>\n",
       "      <td>1.011936</td>\n",
       "      <td>0.300619</td>\n",
       "      <td>102.974410</td>\n",
       "      <td>162.699325</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>model_24_8_7</td>\n",
       "      <td>0.987463</td>\n",
       "      <td>0.808469</td>\n",
       "      <td>0.980767</td>\n",
       "      <td>0.941044</td>\n",
       "      <td>0.970568</td>\n",
       "      <td>0.083835</td>\n",
       "      <td>1.280769</td>\n",
       "      <td>0.167230</td>\n",
       "      <td>0.218856</td>\n",
       "      <td>0.193043</td>\n",
       "      <td>0.439689</td>\n",
       "      <td>0.289543</td>\n",
       "      <td>1.017699</td>\n",
       "      <td>0.301870</td>\n",
       "      <td>86.957800</td>\n",
       "      <td>136.931709</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>model_30_7_6</td>\n",
       "      <td>0.987458</td>\n",
       "      <td>0.797208</td>\n",
       "      <td>0.987466</td>\n",
       "      <td>0.975767</td>\n",
       "      <td>0.984588</td>\n",
       "      <td>0.083867</td>\n",
       "      <td>1.356068</td>\n",
       "      <td>0.145330</td>\n",
       "      <td>0.105845</td>\n",
       "      <td>0.125587</td>\n",
       "      <td>0.608224</td>\n",
       "      <td>0.289598</td>\n",
       "      <td>1.012040</td>\n",
       "      <td>0.301927</td>\n",
       "      <td>102.957043</td>\n",
       "      <td>162.681959</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>model_24_8_6</td>\n",
       "      <td>0.987326</td>\n",
       "      <td>0.809484</td>\n",
       "      <td>0.980142</td>\n",
       "      <td>0.949700</td>\n",
       "      <td>0.972604</td>\n",
       "      <td>0.084750</td>\n",
       "      <td>1.273984</td>\n",
       "      <td>0.172661</td>\n",
       "      <td>0.186722</td>\n",
       "      <td>0.179692</td>\n",
       "      <td>0.481753</td>\n",
       "      <td>0.291119</td>\n",
       "      <td>1.017893</td>\n",
       "      <td>0.303513</td>\n",
       "      <td>86.936088</td>\n",
       "      <td>136.909997</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>model_30_7_16</td>\n",
       "      <td>0.987324</td>\n",
       "      <td>0.809480</td>\n",
       "      <td>0.974112</td>\n",
       "      <td>0.955086</td>\n",
       "      <td>0.969544</td>\n",
       "      <td>0.084763</td>\n",
       "      <td>1.274008</td>\n",
       "      <td>0.300167</td>\n",
       "      <td>0.196177</td>\n",
       "      <td>0.248172</td>\n",
       "      <td>0.408546</td>\n",
       "      <td>0.291140</td>\n",
       "      <td>1.012169</td>\n",
       "      <td>0.303535</td>\n",
       "      <td>102.935799</td>\n",
       "      <td>162.660714</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>model_30_7_17</td>\n",
       "      <td>0.987080</td>\n",
       "      <td>0.809907</td>\n",
       "      <td>0.973219</td>\n",
       "      <td>0.953666</td>\n",
       "      <td>0.968527</td>\n",
       "      <td>0.086399</td>\n",
       "      <td>1.271153</td>\n",
       "      <td>0.310530</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.256455</td>\n",
       "      <td>0.397663</td>\n",
       "      <td>0.293937</td>\n",
       "      <td>1.012404</td>\n",
       "      <td>0.306451</td>\n",
       "      <td>102.897556</td>\n",
       "      <td>162.622471</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>model_24_8_5</td>\n",
       "      <td>0.986894</td>\n",
       "      <td>0.810432</td>\n",
       "      <td>0.979023</td>\n",
       "      <td>0.958253</td>\n",
       "      <td>0.974282</td>\n",
       "      <td>0.087637</td>\n",
       "      <td>1.267641</td>\n",
       "      <td>0.182392</td>\n",
       "      <td>0.154972</td>\n",
       "      <td>0.168682</td>\n",
       "      <td>0.535348</td>\n",
       "      <td>0.296036</td>\n",
       "      <td>1.018502</td>\n",
       "      <td>0.308639</td>\n",
       "      <td>86.869098</td>\n",
       "      <td>136.843007</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>model_30_7_18</td>\n",
       "      <td>0.986838</td>\n",
       "      <td>0.810271</td>\n",
       "      <td>0.972394</td>\n",
       "      <td>0.952363</td>\n",
       "      <td>0.967591</td>\n",
       "      <td>0.088017</td>\n",
       "      <td>1.268719</td>\n",
       "      <td>0.320088</td>\n",
       "      <td>0.208071</td>\n",
       "      <td>0.264080</td>\n",
       "      <td>0.387863</td>\n",
       "      <td>0.296676</td>\n",
       "      <td>1.012636</td>\n",
       "      <td>0.309307</td>\n",
       "      <td>102.860452</td>\n",
       "      <td>162.585367</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>model_30_7_5</td>\n",
       "      <td>0.986683</td>\n",
       "      <td>0.794301</td>\n",
       "      <td>0.989298</td>\n",
       "      <td>0.978075</td>\n",
       "      <td>0.986509</td>\n",
       "      <td>0.089053</td>\n",
       "      <td>1.375513</td>\n",
       "      <td>0.124089</td>\n",
       "      <td>0.095765</td>\n",
       "      <td>0.109927</td>\n",
       "      <td>0.641014</td>\n",
       "      <td>0.298418</td>\n",
       "      <td>1.012785</td>\n",
       "      <td>0.311122</td>\n",
       "      <td>102.837046</td>\n",
       "      <td>162.561961</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>model_30_7_19</td>\n",
       "      <td>0.986602</td>\n",
       "      <td>0.810582</td>\n",
       "      <td>0.971636</td>\n",
       "      <td>0.951171</td>\n",
       "      <td>0.966732</td>\n",
       "      <td>0.089591</td>\n",
       "      <td>1.266638</td>\n",
       "      <td>0.328884</td>\n",
       "      <td>0.213277</td>\n",
       "      <td>0.271080</td>\n",
       "      <td>0.379041</td>\n",
       "      <td>0.299318</td>\n",
       "      <td>1.012862</td>\n",
       "      <td>0.312060</td>\n",
       "      <td>102.824999</td>\n",
       "      <td>162.549915</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>model_30_7_20</td>\n",
       "      <td>0.986376</td>\n",
       "      <td>0.810849</td>\n",
       "      <td>0.970939</td>\n",
       "      <td>0.950083</td>\n",
       "      <td>0.965945</td>\n",
       "      <td>0.091104</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>0.336962</td>\n",
       "      <td>0.218031</td>\n",
       "      <td>0.277496</td>\n",
       "      <td>0.371091</td>\n",
       "      <td>0.301835</td>\n",
       "      <td>1.013079</td>\n",
       "      <td>0.314685</td>\n",
       "      <td>102.791501</td>\n",
       "      <td>162.516416</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>model_30_7_21</td>\n",
       "      <td>0.986161</td>\n",
       "      <td>0.811078</td>\n",
       "      <td>0.970301</td>\n",
       "      <td>0.949091</td>\n",
       "      <td>0.965225</td>\n",
       "      <td>0.092544</td>\n",
       "      <td>1.263323</td>\n",
       "      <td>0.344363</td>\n",
       "      <td>0.222363</td>\n",
       "      <td>0.283363</td>\n",
       "      <td>0.363938</td>\n",
       "      <td>0.304211</td>\n",
       "      <td>1.013286</td>\n",
       "      <td>0.317162</td>\n",
       "      <td>102.760138</td>\n",
       "      <td>162.485053</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>model_24_8_4</td>\n",
       "      <td>0.986080</td>\n",
       "      <td>0.811270</td>\n",
       "      <td>0.977264</td>\n",
       "      <td>0.966538</td>\n",
       "      <td>0.975461</td>\n",
       "      <td>0.093085</td>\n",
       "      <td>1.262038</td>\n",
       "      <td>0.197684</td>\n",
       "      <td>0.124216</td>\n",
       "      <td>0.160950</td>\n",
       "      <td>0.593907</td>\n",
       "      <td>0.305098</td>\n",
       "      <td>1.019652</td>\n",
       "      <td>0.318087</td>\n",
       "      <td>86.748485</td>\n",
       "      <td>136.722394</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>model_24_9_1</td>\n",
       "      <td>0.986005</td>\n",
       "      <td>0.793228</td>\n",
       "      <td>0.941357</td>\n",
       "      <td>0.978820</td>\n",
       "      <td>0.976833</td>\n",
       "      <td>0.093588</td>\n",
       "      <td>1.382687</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.029290</td>\n",
       "      <td>0.023109</td>\n",
       "      <td>0.482255</td>\n",
       "      <td>0.305921</td>\n",
       "      <td>1.019758</td>\n",
       "      <td>0.318945</td>\n",
       "      <td>86.737708</td>\n",
       "      <td>136.711616</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>model_30_7_22</td>\n",
       "      <td>0.985957</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.969717</td>\n",
       "      <td>0.948188</td>\n",
       "      <td>0.964567</td>\n",
       "      <td>0.093904</td>\n",
       "      <td>1.262004</td>\n",
       "      <td>0.351137</td>\n",
       "      <td>0.226306</td>\n",
       "      <td>0.288721</td>\n",
       "      <td>0.357498</td>\n",
       "      <td>0.306438</td>\n",
       "      <td>1.013481</td>\n",
       "      <td>0.319484</td>\n",
       "      <td>102.730958</td>\n",
       "      <td>162.455873</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>model_30_7_23</td>\n",
       "      <td>0.985766</td>\n",
       "      <td>0.811446</td>\n",
       "      <td>0.969183</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.095180</td>\n",
       "      <td>1.260864</td>\n",
       "      <td>0.357322</td>\n",
       "      <td>0.229890</td>\n",
       "      <td>0.293606</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>0.308513</td>\n",
       "      <td>1.013664</td>\n",
       "      <td>0.321647</td>\n",
       "      <td>102.703968</td>\n",
       "      <td>162.428883</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>model_30_7_24</td>\n",
       "      <td>0.985588</td>\n",
       "      <td>0.811593</td>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.946623</td>\n",
       "      <td>0.963422</td>\n",
       "      <td>0.096370</td>\n",
       "      <td>1.259877</td>\n",
       "      <td>0.362963</td>\n",
       "      <td>0.233142</td>\n",
       "      <td>0.298052</td>\n",
       "      <td>0.346480</td>\n",
       "      <td>0.310435</td>\n",
       "      <td>1.013835</td>\n",
       "      <td>0.323651</td>\n",
       "      <td>102.679117</td>\n",
       "      <td>162.404033</td>\n",
       "      <td>Hidden Size=[12], regularizer=0.2, learning_ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>model_24_8_3</td>\n",
       "      <td>0.984776</td>\n",
       "      <td>0.811941</td>\n",
       "      <td>0.974692</td>\n",
       "      <td>0.974369</td>\n",
       "      <td>0.975972</td>\n",
       "      <td>0.101805</td>\n",
       "      <td>1.257550</td>\n",
       "      <td>0.220055</td>\n",
       "      <td>0.095147</td>\n",
       "      <td>0.157601</td>\n",
       "      <td>0.657710</td>\n",
       "      <td>0.319069</td>\n",
       "      <td>1.021493</td>\n",
       "      <td>0.332652</td>\n",
       "      <td>86.569391</td>\n",
       "      <td>136.543300</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>model_24_9_0</td>\n",
       "      <td>0.983728</td>\n",
       "      <td>0.794726</td>\n",
       "      <td>0.983836</td>\n",
       "      <td>0.992515</td>\n",
       "      <td>0.992473</td>\n",
       "      <td>0.108812</td>\n",
       "      <td>1.372667</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.473353</td>\n",
       "      <td>0.329867</td>\n",
       "      <td>1.022972</td>\n",
       "      <td>0.343910</td>\n",
       "      <td>86.436264</td>\n",
       "      <td>136.410173</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>model_24_8_2</td>\n",
       "      <td>0.982855</td>\n",
       "      <td>0.812377</td>\n",
       "      <td>0.971099</td>\n",
       "      <td>0.981547</td>\n",
       "      <td>0.975622</td>\n",
       "      <td>0.114646</td>\n",
       "      <td>1.254638</td>\n",
       "      <td>0.251291</td>\n",
       "      <td>0.068501</td>\n",
       "      <td>0.159896</td>\n",
       "      <td>0.726953</td>\n",
       "      <td>0.338594</td>\n",
       "      <td>1.024204</td>\n",
       "      <td>0.353008</td>\n",
       "      <td>86.331817</td>\n",
       "      <td>136.305726</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>model_24_8_1</td>\n",
       "      <td>0.980170</td>\n",
       "      <td>0.812492</td>\n",
       "      <td>0.966254</td>\n",
       "      <td>0.987867</td>\n",
       "      <td>0.974199</td>\n",
       "      <td>0.132604</td>\n",
       "      <td>1.253870</td>\n",
       "      <td>0.293423</td>\n",
       "      <td>0.045039</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.802313</td>\n",
       "      <td>0.364148</td>\n",
       "      <td>1.027995</td>\n",
       "      <td>0.379650</td>\n",
       "      <td>86.040781</td>\n",
       "      <td>136.014690</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>model_28_8_0</td>\n",
       "      <td>0.978698</td>\n",
       "      <td>0.832316</td>\n",
       "      <td>0.981216</td>\n",
       "      <td>0.957011</td>\n",
       "      <td>0.970086</td>\n",
       "      <td>0.142445</td>\n",
       "      <td>1.121301</td>\n",
       "      <td>0.109613</td>\n",
       "      <td>0.230438</td>\n",
       "      <td>0.170026</td>\n",
       "      <td>0.357597</td>\n",
       "      <td>0.377419</td>\n",
       "      <td>1.024345</td>\n",
       "      <td>0.393486</td>\n",
       "      <td>93.897601</td>\n",
       "      <td>148.747013</td>\n",
       "      <td>Hidden Size=[11], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>model_28_8_1</td>\n",
       "      <td>0.978575</td>\n",
       "      <td>0.836341</td>\n",
       "      <td>0.971543</td>\n",
       "      <td>0.946891</td>\n",
       "      <td>0.960349</td>\n",
       "      <td>0.143270</td>\n",
       "      <td>1.094386</td>\n",
       "      <td>0.166054</td>\n",
       "      <td>0.284688</td>\n",
       "      <td>0.225371</td>\n",
       "      <td>0.386981</td>\n",
       "      <td>0.378510</td>\n",
       "      <td>1.024486</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>93.886055</td>\n",
       "      <td>148.735467</td>\n",
       "      <td>Hidden Size=[11], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>model_28_8_2</td>\n",
       "      <td>0.977671</td>\n",
       "      <td>0.839171</td>\n",
       "      <td>0.960954</td>\n",
       "      <td>0.935509</td>\n",
       "      <td>0.949546</td>\n",
       "      <td>0.149313</td>\n",
       "      <td>1.075463</td>\n",
       "      <td>0.227843</td>\n",
       "      <td>0.345700</td>\n",
       "      <td>0.286771</td>\n",
       "      <td>0.415332</td>\n",
       "      <td>0.386411</td>\n",
       "      <td>1.025519</td>\n",
       "      <td>0.402861</td>\n",
       "      <td>93.803416</td>\n",
       "      <td>148.652828</td>\n",
       "      <td>Hidden Size=[11], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>model_24_8_0</td>\n",
       "      <td>0.976547</td>\n",
       "      <td>0.812183</td>\n",
       "      <td>0.959907</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.971479</td>\n",
       "      <td>0.156832</td>\n",
       "      <td>1.255934</td>\n",
       "      <td>0.348608</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.187072</td>\n",
       "      <td>0.883152</td>\n",
       "      <td>0.396020</td>\n",
       "      <td>1.033110</td>\n",
       "      <td>0.412879</td>\n",
       "      <td>85.705162</td>\n",
       "      <td>135.679071</td>\n",
       "      <td>Hidden Size=[10], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>model_28_8_3</td>\n",
       "      <td>0.976120</td>\n",
       "      <td>0.840999</td>\n",
       "      <td>0.949900</td>\n",
       "      <td>0.922659</td>\n",
       "      <td>0.937812</td>\n",
       "      <td>0.159683</td>\n",
       "      <td>1.063240</td>\n",
       "      <td>0.292348</td>\n",
       "      <td>0.414580</td>\n",
       "      <td>0.353464</td>\n",
       "      <td>0.441966</td>\n",
       "      <td>0.399603</td>\n",
       "      <td>1.027291</td>\n",
       "      <td>0.416615</td>\n",
       "      <td>93.669132</td>\n",
       "      <td>148.518544</td>\n",
       "      <td>Hidden Size=[11], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>model_9_9_12</td>\n",
       "      <td>0.973778</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>0.944960</td>\n",
       "      <td>0.991165</td>\n",
       "      <td>0.977282</td>\n",
       "      <td>0.175347</td>\n",
       "      <td>0.970115</td>\n",
       "      <td>0.318344</td>\n",
       "      <td>0.107295</td>\n",
       "      <td>0.212819</td>\n",
       "      <td>0.903113</td>\n",
       "      <td>0.418744</td>\n",
       "      <td>1.125866</td>\n",
       "      <td>0.436571</td>\n",
       "      <td>61.481981</td>\n",
       "      <td>96.829380</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>model_9_9_11</td>\n",
       "      <td>0.973538</td>\n",
       "      <td>0.854560</td>\n",
       "      <td>0.945755</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.977473</td>\n",
       "      <td>0.176953</td>\n",
       "      <td>0.972560</td>\n",
       "      <td>0.313744</td>\n",
       "      <td>0.108317</td>\n",
       "      <td>0.211030</td>\n",
       "      <td>0.915410</td>\n",
       "      <td>0.420658</td>\n",
       "      <td>1.127019</td>\n",
       "      <td>0.438567</td>\n",
       "      <td>61.463738</td>\n",
       "      <td>96.811137</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>model_9_9_10</td>\n",
       "      <td>0.973280</td>\n",
       "      <td>0.854178</td>\n",
       "      <td>0.946504</td>\n",
       "      <td>0.990980</td>\n",
       "      <td>0.977639</td>\n",
       "      <td>0.178679</td>\n",
       "      <td>0.975110</td>\n",
       "      <td>0.309413</td>\n",
       "      <td>0.109535</td>\n",
       "      <td>0.209474</td>\n",
       "      <td>0.928803</td>\n",
       "      <td>0.422704</td>\n",
       "      <td>1.128257</td>\n",
       "      <td>0.440699</td>\n",
       "      <td>61.444334</td>\n",
       "      <td>96.791733</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>model_9_9_9</td>\n",
       "      <td>0.973004</td>\n",
       "      <td>0.853781</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.990864</td>\n",
       "      <td>0.977780</td>\n",
       "      <td>0.180525</td>\n",
       "      <td>0.977770</td>\n",
       "      <td>0.305360</td>\n",
       "      <td>0.110953</td>\n",
       "      <td>0.208157</td>\n",
       "      <td>0.942346</td>\n",
       "      <td>0.424883</td>\n",
       "      <td>1.129583</td>\n",
       "      <td>0.442971</td>\n",
       "      <td>61.423770</td>\n",
       "      <td>96.771169</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>model_9_9_8</td>\n",
       "      <td>0.972709</td>\n",
       "      <td>0.853366</td>\n",
       "      <td>0.947855</td>\n",
       "      <td>0.990730</td>\n",
       "      <td>0.977894</td>\n",
       "      <td>0.182498</td>\n",
       "      <td>0.980543</td>\n",
       "      <td>0.301602</td>\n",
       "      <td>0.112579</td>\n",
       "      <td>0.207091</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.427198</td>\n",
       "      <td>1.130999</td>\n",
       "      <td>0.445385</td>\n",
       "      <td>61.402030</td>\n",
       "      <td>96.749428</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>model_9_9_7</td>\n",
       "      <td>0.972394</td>\n",
       "      <td>0.852934</td>\n",
       "      <td>0.948451</td>\n",
       "      <td>0.990579</td>\n",
       "      <td>0.977980</td>\n",
       "      <td>0.184601</td>\n",
       "      <td>0.983432</td>\n",
       "      <td>0.298150</td>\n",
       "      <td>0.114416</td>\n",
       "      <td>0.206283</td>\n",
       "      <td>0.969904</td>\n",
       "      <td>0.429652</td>\n",
       "      <td>1.132509</td>\n",
       "      <td>0.447944</td>\n",
       "      <td>61.379115</td>\n",
       "      <td>96.726514</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>model_9_9_6</td>\n",
       "      <td>0.972060</td>\n",
       "      <td>0.852484</td>\n",
       "      <td>0.948993</td>\n",
       "      <td>0.990409</td>\n",
       "      <td>0.978037</td>\n",
       "      <td>0.186838</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.295019</td>\n",
       "      <td>0.116470</td>\n",
       "      <td>0.205745</td>\n",
       "      <td>0.983917</td>\n",
       "      <td>0.432248</td>\n",
       "      <td>1.134114</td>\n",
       "      <td>0.450650</td>\n",
       "      <td>61.355025</td>\n",
       "      <td>96.702424</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>model_9_9_5</td>\n",
       "      <td>0.971704</td>\n",
       "      <td>0.852016</td>\n",
       "      <td>0.949476</td>\n",
       "      <td>0.990222</td>\n",
       "      <td>0.978065</td>\n",
       "      <td>0.189213</td>\n",
       "      <td>0.989572</td>\n",
       "      <td>0.292223</td>\n",
       "      <td>0.118749</td>\n",
       "      <td>0.205486</td>\n",
       "      <td>0.998093</td>\n",
       "      <td>0.434986</td>\n",
       "      <td>1.135819</td>\n",
       "      <td>0.453505</td>\n",
       "      <td>61.329761</td>\n",
       "      <td>96.677160</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>model_9_9_4</td>\n",
       "      <td>0.971328</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>0.949899</td>\n",
       "      <td>0.990015</td>\n",
       "      <td>0.978062</td>\n",
       "      <td>0.191731</td>\n",
       "      <td>0.992832</td>\n",
       "      <td>0.289776</td>\n",
       "      <td>0.121258</td>\n",
       "      <td>0.205517</td>\n",
       "      <td>1.012430</td>\n",
       "      <td>0.437871</td>\n",
       "      <td>1.137627</td>\n",
       "      <td>0.456512</td>\n",
       "      <td>61.303323</td>\n",
       "      <td>96.650722</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>model_9_9_3</td>\n",
       "      <td>0.970929</td>\n",
       "      <td>0.851021</td>\n",
       "      <td>0.950260</td>\n",
       "      <td>0.989789</td>\n",
       "      <td>0.978026</td>\n",
       "      <td>0.194396</td>\n",
       "      <td>0.996222</td>\n",
       "      <td>0.287692</td>\n",
       "      <td>0.124002</td>\n",
       "      <td>0.205847</td>\n",
       "      <td>1.026930</td>\n",
       "      <td>0.440903</td>\n",
       "      <td>1.139539</td>\n",
       "      <td>0.459674</td>\n",
       "      <td>61.275718</td>\n",
       "      <td>96.623117</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>model_9_9_2</td>\n",
       "      <td>0.970508</td>\n",
       "      <td>0.850494</td>\n",
       "      <td>0.950555</td>\n",
       "      <td>0.989543</td>\n",
       "      <td>0.977958</td>\n",
       "      <td>0.197212</td>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.285987</td>\n",
       "      <td>0.126990</td>\n",
       "      <td>0.206488</td>\n",
       "      <td>1.041596</td>\n",
       "      <td>0.444085</td>\n",
       "      <td>1.141561</td>\n",
       "      <td>0.462991</td>\n",
       "      <td>61.246956</td>\n",
       "      <td>96.594355</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>model_9_9_1</td>\n",
       "      <td>0.970064</td>\n",
       "      <td>0.849946</td>\n",
       "      <td>0.950781</td>\n",
       "      <td>0.989277</td>\n",
       "      <td>0.977855</td>\n",
       "      <td>0.200183</td>\n",
       "      <td>1.003415</td>\n",
       "      <td>0.284675</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.207451</td>\n",
       "      <td>1.056427</td>\n",
       "      <td>0.447419</td>\n",
       "      <td>1.143694</td>\n",
       "      <td>0.466466</td>\n",
       "      <td>61.217043</td>\n",
       "      <td>96.564442</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>model_9_9_0</td>\n",
       "      <td>0.969595</td>\n",
       "      <td>0.849376</td>\n",
       "      <td>0.950937</td>\n",
       "      <td>0.988989</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>0.203316</td>\n",
       "      <td>1.007227</td>\n",
       "      <td>0.283772</td>\n",
       "      <td>0.133725</td>\n",
       "      <td>0.208748</td>\n",
       "      <td>1.071428</td>\n",
       "      <td>0.450906</td>\n",
       "      <td>1.145942</td>\n",
       "      <td>0.470102</td>\n",
       "      <td>61.185987</td>\n",
       "      <td>96.533386</td>\n",
       "      <td>Hidden Size=[7], regularizer=0.2, learning_rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>model_28_9_3</td>\n",
       "      <td>0.961910</td>\n",
       "      <td>0.828008</td>\n",
       "      <td>0.961803</td>\n",
       "      <td>0.916115</td>\n",
       "      <td>0.958952</td>\n",
       "      <td>0.254711</td>\n",
       "      <td>1.150113</td>\n",
       "      <td>0.100883</td>\n",
       "      <td>0.127625</td>\n",
       "      <td>0.114254</td>\n",
       "      <td>0.500241</td>\n",
       "      <td>0.504689</td>\n",
       "      <td>1.043532</td>\n",
       "      <td>0.526174</td>\n",
       "      <td>92.735254</td>\n",
       "      <td>147.584667</td>\n",
       "      <td>Hidden Size=[11], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>model_28_9_2</td>\n",
       "      <td>0.955502</td>\n",
       "      <td>0.827903</td>\n",
       "      <td>0.973665</td>\n",
       "      <td>0.932207</td>\n",
       "      <td>0.968978</td>\n",
       "      <td>0.297556</td>\n",
       "      <td>1.150817</td>\n",
       "      <td>0.069554</td>\n",
       "      <td>0.103142</td>\n",
       "      <td>0.086348</td>\n",
       "      <td>0.536836</td>\n",
       "      <td>0.545487</td>\n",
       "      <td>1.050854</td>\n",
       "      <td>0.568709</td>\n",
       "      <td>92.424307</td>\n",
       "      <td>147.273719</td>\n",
       "      <td>Hidden Size=[11], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>model_28_9_1</td>\n",
       "      <td>0.947055</td>\n",
       "      <td>0.826623</td>\n",
       "      <td>0.984987</td>\n",
       "      <td>0.944160</td>\n",
       "      <td>0.977616</td>\n",
       "      <td>0.354043</td>\n",
       "      <td>1.159375</td>\n",
       "      <td>0.039650</td>\n",
       "      <td>0.084957</td>\n",
       "      <td>0.062304</td>\n",
       "      <td>0.576012</td>\n",
       "      <td>0.595015</td>\n",
       "      <td>1.060509</td>\n",
       "      <td>0.620346</td>\n",
       "      <td>92.076673</td>\n",
       "      <td>146.926086</td>\n",
       "      <td>Hidden Size=[11], regularizer=0.05, learning_r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model        r2    r2_sup   r2_test    r2_val     r2_vt  \\\n",
       "75   model_30_7_10  0.988412  0.804699  0.981097  0.966296  0.977518   \n",
       "76    model_30_7_9  0.988396  0.803299  0.982553  0.968587  0.979168   \n",
       "77   model_30_7_11  0.988338  0.805871  0.979728  0.964110  0.975958   \n",
       "78    model_30_7_8  0.988260  0.801626  0.984098  0.970958  0.980902   \n",
       "79   model_30_7_12  0.988199  0.806856  0.978443  0.962044  0.974490   \n",
       "80   model_30_7_13  0.988014  0.807686  0.977242  0.960107  0.973116   \n",
       "81    model_30_7_7  0.987963  0.799620  0.985734  0.973369  0.982713   \n",
       "84   model_30_7_14  0.987800  0.808386  0.976121  0.958303  0.971835   \n",
       "85   model_30_7_15  0.987567  0.808978  0.975079  0.956630  0.970645   \n",
       "86    model_24_8_7  0.987463  0.808469  0.980767  0.941044  0.970568   \n",
       "87    model_30_7_6  0.987458  0.797208  0.987466  0.975767  0.984588   \n",
       "90    model_24_8_6  0.987326  0.809484  0.980142  0.949700  0.972604   \n",
       "91   model_30_7_16  0.987324  0.809480  0.974112  0.955086  0.969544   \n",
       "94   model_30_7_17  0.987080  0.809907  0.973219  0.953666  0.968527   \n",
       "95    model_24_8_5  0.986894  0.810432  0.979023  0.958253  0.974282   \n",
       "96   model_30_7_18  0.986838  0.810271  0.972394  0.952363  0.967591   \n",
       "98    model_30_7_5  0.986683  0.794301  0.989298  0.978075  0.986509   \n",
       "99   model_30_7_19  0.986602  0.810582  0.971636  0.951171  0.966732   \n",
       "100  model_30_7_20  0.986376  0.810849  0.970939  0.950083  0.965945   \n",
       "103  model_30_7_21  0.986161  0.811078  0.970301  0.949091  0.965225   \n",
       "104   model_24_8_4  0.986080  0.811270  0.977264  0.966538  0.975461   \n",
       "105   model_24_9_1  0.986005  0.793228  0.941357  0.978820  0.976833   \n",
       "106  model_30_7_22  0.985957  0.811275  0.969717  0.948188  0.964567   \n",
       "108  model_30_7_23  0.985766  0.811446  0.969183  0.947368  0.963968   \n",
       "109  model_30_7_24  0.985588  0.811593  0.968697  0.946623  0.963422   \n",
       "113   model_24_8_3  0.984776  0.811941  0.974692  0.974369  0.975972   \n",
       "117   model_24_9_0  0.983728  0.794726  0.983836  0.992515  0.992473   \n",
       "121   model_24_8_2  0.982855  0.812377  0.971099  0.981547  0.975622   \n",
       "136   model_24_8_1  0.980170  0.812492  0.966254  0.987867  0.974199   \n",
       "140   model_28_8_0  0.978698  0.832316  0.981216  0.957011  0.970086   \n",
       "141   model_28_8_1  0.978575  0.836341  0.971543  0.946891  0.960349   \n",
       "145   model_28_8_2  0.977671  0.839171  0.960954  0.935509  0.949546   \n",
       "153   model_24_8_0  0.976547  0.812183  0.959907  0.993121  0.971479   \n",
       "156   model_28_8_3  0.976120  0.840999  0.949900  0.922659  0.937812   \n",
       "186   model_9_9_12  0.973778  0.854925  0.944960  0.991165  0.977282   \n",
       "188   model_9_9_11  0.973538  0.854560  0.945755  0.991081  0.977473   \n",
       "190   model_9_9_10  0.973280  0.854178  0.946504  0.990980  0.977639   \n",
       "193    model_9_9_9  0.973004  0.853781  0.947205  0.990864  0.977780   \n",
       "197    model_9_9_8  0.972709  0.853366  0.947855  0.990730  0.977894   \n",
       "199    model_9_9_7  0.972394  0.852934  0.948451  0.990579  0.977980   \n",
       "202    model_9_9_6  0.972060  0.852484  0.948993  0.990409  0.978037   \n",
       "205    model_9_9_5  0.971704  0.852016  0.949476  0.990222  0.978065   \n",
       "207    model_9_9_4  0.971328  0.851528  0.949899  0.990015  0.978062   \n",
       "208    model_9_9_3  0.970929  0.851021  0.950260  0.989789  0.978026   \n",
       "214    model_9_9_2  0.970508  0.850494  0.950555  0.989543  0.977958   \n",
       "220    model_9_9_1  0.970064  0.849946  0.950781  0.989277  0.977855   \n",
       "223    model_9_9_0  0.969595  0.849376  0.950937  0.988989  0.977717   \n",
       "269   model_28_9_3  0.961910  0.828008  0.961803  0.916115  0.958952   \n",
       "281   model_28_9_2  0.955502  0.827903  0.973665  0.932207  0.968978   \n",
       "288   model_28_9_1  0.947055  0.826623  0.984987  0.944160  0.977616   \n",
       "\n",
       "          mse   mse_sup  mse_test   mse_val    mse_vt      mape      rmse  \\\n",
       "75   0.077488  1.305981  0.219178  0.147212  0.183195  0.503922  0.278367   \n",
       "76   0.077593  1.315337  0.202296  0.137205  0.169750  0.526308  0.278555   \n",
       "77   0.077983  1.298140  0.235055  0.156762  0.195908  0.483683  0.279254   \n",
       "78   0.078506  1.326527  0.184385  0.126851  0.155618  0.551029  0.280189   \n",
       "79   0.078913  1.291553  0.249950  0.165786  0.207868  0.465406  0.280915   \n",
       "80   0.080147  1.286007  0.263884  0.174246  0.219065  0.448909  0.283103   \n",
       "81   0.080488  1.339942  0.165412  0.116318  0.140865  0.578278  0.283705   \n",
       "84   0.081583  1.281326  0.276878  0.182127  0.229502  0.434031  0.285627   \n",
       "85   0.083142  1.277367  0.288962  0.189434  0.239198  0.420625  0.288344   \n",
       "86   0.083835  1.280769  0.167230  0.218856  0.193043  0.439689  0.289543   \n",
       "87   0.083867  1.356068  0.145330  0.105845  0.125587  0.608224  0.289598   \n",
       "90   0.084750  1.273984  0.172661  0.186722  0.179692  0.481753  0.291119   \n",
       "91   0.084763  1.274008  0.300167  0.196177  0.248172  0.408546  0.291140   \n",
       "94   0.086399  1.271153  0.310530  0.202381  0.256455  0.397663  0.293937   \n",
       "95   0.087637  1.267641  0.182392  0.154972  0.168682  0.535348  0.296036   \n",
       "96   0.088017  1.268719  0.320088  0.208071  0.264080  0.387863  0.296676   \n",
       "98   0.089053  1.375513  0.124089  0.095765  0.109927  0.641014  0.298418   \n",
       "99   0.089591  1.266638  0.328884  0.213277  0.271080  0.379041  0.299318   \n",
       "100  0.091104  1.264855  0.336962  0.218031  0.277496  0.371091  0.301835   \n",
       "103  0.092544  1.263323  0.344363  0.222363  0.283363  0.363938  0.304211   \n",
       "104  0.093085  1.262038  0.197684  0.124216  0.160950  0.593907  0.305098   \n",
       "105  0.093588  1.382687  0.016927  0.029290  0.023109  0.482255  0.305921   \n",
       "106  0.093904  1.262004  0.351137  0.226306  0.288721  0.357498  0.306438   \n",
       "108  0.095180  1.260864  0.357322  0.229890  0.293606  0.351700  0.308513   \n",
       "109  0.096370  1.259877  0.362963  0.233142  0.298052  0.346480  0.310435   \n",
       "113  0.101805  1.257550  0.220055  0.095147  0.157601  0.657710  0.319069   \n",
       "117  0.108812  1.372667  0.004666  0.010351  0.007508  0.473353  0.329867   \n",
       "121  0.114646  1.254638  0.251291  0.068501  0.159896  0.726953  0.338594   \n",
       "136  0.132604  1.253870  0.293423  0.045039  0.169231  0.802313  0.364148   \n",
       "140  0.142445  1.121301  0.109613  0.230438  0.170026  0.357597  0.377419   \n",
       "141  0.143270  1.094386  0.166054  0.284688  0.225371  0.386981  0.378510   \n",
       "145  0.149313  1.075463  0.227843  0.345700  0.286771  0.415332  0.386411   \n",
       "153  0.156832  1.255934  0.348608  0.025537  0.187072  0.883152  0.396020   \n",
       "156  0.159683  1.063240  0.292348  0.414580  0.353464  0.441966  0.399603   \n",
       "186  0.175347  0.970115  0.318344  0.107295  0.212819  0.903113  0.418744   \n",
       "188  0.176953  0.972560  0.313744  0.108317  0.211030  0.915410  0.420658   \n",
       "190  0.178679  0.975110  0.309413  0.109535  0.209474  0.928803  0.422704   \n",
       "193  0.180525  0.977770  0.305360  0.110953  0.208157  0.942346  0.424883   \n",
       "197  0.182498  0.980543  0.301602  0.112579  0.207091  0.956048  0.427198   \n",
       "199  0.184601  0.983432  0.298150  0.114416  0.206283  0.969904  0.429652   \n",
       "202  0.186838  0.986441  0.295019  0.116470  0.205745  0.983917  0.432248   \n",
       "205  0.189213  0.989572  0.292223  0.118749  0.205486  0.998093  0.434986   \n",
       "207  0.191731  0.992832  0.289776  0.121258  0.205517  1.012430  0.437871   \n",
       "208  0.194396  0.996222  0.287692  0.124002  0.205847  1.026930  0.440903   \n",
       "214  0.197212  0.999748  0.285987  0.126990  0.206488  1.041596  0.444085   \n",
       "220  0.200183  1.003415  0.284675  0.130228  0.207451  1.056427  0.447419   \n",
       "223  0.203316  1.007227  0.283772  0.133725  0.208748  1.071428  0.450906   \n",
       "269  0.254711  1.150113  0.100883  0.127625  0.114254  0.500241  0.504689   \n",
       "281  0.297556  1.150817  0.069554  0.103142  0.086348  0.536836  0.545487   \n",
       "288  0.354043  1.159375  0.039650  0.084957  0.062304  0.576012  0.595015   \n",
       "\n",
       "       r2_adj       rsd         aic         bic  \\\n",
       "75   1.011124  0.290217  103.115264  162.840180   \n",
       "76   1.011139  0.290414  103.112559  162.837475   \n",
       "77   1.011195  0.291143  103.102527  162.827443   \n",
       "78   1.011270  0.292117  103.089163  162.814079   \n",
       "79   1.011329  0.292874  103.078819  162.803734   \n",
       "80   1.011506  0.295155  103.047783  162.772698   \n",
       "81   1.011555  0.295783  103.039285  162.764201   \n",
       "84   1.011712  0.297787  103.012270  162.737185   \n",
       "85   1.011936  0.300619  102.974410  162.699325   \n",
       "86   1.017699  0.301870   86.957800  136.931709   \n",
       "87   1.012040  0.301927  102.957043  162.681959   \n",
       "90   1.017893  0.303513   86.936088  136.909997   \n",
       "91   1.012169  0.303535  102.935799  162.660714   \n",
       "94   1.012404  0.306451  102.897556  162.622471   \n",
       "95   1.018502  0.308639   86.869098  136.843007   \n",
       "96   1.012636  0.309307  102.860452  162.585367   \n",
       "98   1.012785  0.311122  102.837046  162.561961   \n",
       "99   1.012862  0.312060  102.824999  162.549915   \n",
       "100  1.013079  0.314685  102.791501  162.516416   \n",
       "103  1.013286  0.317162  102.760138  162.485053   \n",
       "104  1.019652  0.318087   86.748485  136.722394   \n",
       "105  1.019758  0.318945   86.737708  136.711616   \n",
       "106  1.013481  0.319484  102.730958  162.455873   \n",
       "108  1.013664  0.321647  102.703968  162.428883   \n",
       "109  1.013835  0.323651  102.679117  162.404033   \n",
       "113  1.021493  0.332652   86.569391  136.543300   \n",
       "117  1.022972  0.343910   86.436264  136.410173   \n",
       "121  1.024204  0.353008   86.331817  136.305726   \n",
       "136  1.027995  0.379650   86.040781  136.014690   \n",
       "140  1.024345  0.393486   93.897601  148.747013   \n",
       "141  1.024486  0.394624   93.886055  148.735467   \n",
       "145  1.025519  0.402861   93.803416  148.652828   \n",
       "153  1.033110  0.412879   85.705162  135.679071   \n",
       "156  1.027291  0.416615   93.669132  148.518544   \n",
       "186  1.125866  0.436571   61.481981   96.829380   \n",
       "188  1.127019  0.438567   61.463738   96.811137   \n",
       "190  1.128257  0.440699   61.444334   96.791733   \n",
       "193  1.129583  0.442971   61.423770   96.771169   \n",
       "197  1.130999  0.445385   61.402030   96.749428   \n",
       "199  1.132509  0.447944   61.379115   96.726514   \n",
       "202  1.134114  0.450650   61.355025   96.702424   \n",
       "205  1.135819  0.453505   61.329761   96.677160   \n",
       "207  1.137627  0.456512   61.303323   96.650722   \n",
       "208  1.139539  0.459674   61.275718   96.623117   \n",
       "214  1.141561  0.462991   61.246956   96.594355   \n",
       "220  1.143694  0.466466   61.217043   96.564442   \n",
       "223  1.145942  0.470102   61.185987   96.533386   \n",
       "269  1.043532  0.526174   92.735254  147.584667   \n",
       "281  1.050854  0.568709   92.424307  147.273719   \n",
       "288  1.060509  0.620346   92.076673  146.926086   \n",
       "\n",
       "                                          Architecture  \n",
       "75   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "76   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "77   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "78   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "79   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "80   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "81   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "84   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "85   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "86   Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "87   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "90   Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "91   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "94   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "95   Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "96   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "98   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "99   Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "100  Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "103  Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "104  Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "105  Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "106  Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "108  Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "109  Hidden Size=[12], regularizer=0.2, learning_ra...  \n",
       "113  Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "117  Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "121  Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "136  Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "140  Hidden Size=[11], regularizer=0.05, learning_r...  \n",
       "141  Hidden Size=[11], regularizer=0.05, learning_r...  \n",
       "145  Hidden Size=[11], regularizer=0.05, learning_r...  \n",
       "153  Hidden Size=[10], regularizer=0.05, learning_r...  \n",
       "156  Hidden Size=[11], regularizer=0.05, learning_r...  \n",
       "186  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "188  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "190  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "193  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "197  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "199  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "202  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "205  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "207  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "208  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "214  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "220  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "223  Hidden Size=[7], regularizer=0.2, learning_rat...  \n",
       "269  Hidden Size=[11], regularizer=0.05, learning_r...  \n",
       "281  Hidden Size=[11], regularizer=0.05, learning_r...  \n",
       "288  Hidden Size=[11], regularizer=0.05, learning_r...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analize = Analizer(0.9)\n",
    "analize.Analize()\n",
    "analize.clean_folder(subfolder=\"dataset\", extension=\"pkl\")\n",
    "analize.clean_folder(subfolder=\"results\", extension=\"xlsx\")\n",
    "analize.clean_folder(subfolder=\"results\", extension=\"txt\")\n",
    "analize.clean_folder(subfolder=\"models\", extension=\"keras\", remove_last=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
